# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IPB3FpIXQDdQkBI6lqh10szhCiBuyySW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from scipy.stats import mstats
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.model_selection import GridSearchCV
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

!wget 'https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/zkwgkjkjn9-2.zip'
!pip install patool
import patoolib
patoolib.extract_archive('/kaggle/working/zkwgkjkjn9-2.zip')

patoolib.extract_archive('/kaggle/working/zkwgkjkjn9-2/Thermal Camera Images/Mixture.zip')

patoolib.extract_archive('/kaggle/working/zkwgkjkjn9-2/Thermal Camera Images/Perfume.zip')

patoolib.extract_archive('/kaggle/working/zkwgkjkjn9-2/Thermal Camera Images/Smoke.zip')

patoolib.extract_archive('/kaggle/working/zkwgkjkjn9-2/Thermal Camera Images/NoGas.zip')

df = pd.read_csv("/kaggle/working/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv")
df

df = df.drop(['Serial Number', 'Corresponding Image Name'], axis=1)
X = df.drop(['Gas'], axis=1)
y = df['Gas']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
for column in ['MQ2', 'MQ5', 'MQ7', 'MQ8', 'MQ135']:
    X_train[column] = mstats.winsorize(X_train[column], limits=[0.05, 0.05])
    X_test[column] = mstats.winsorize(X_test[column], limits=[0.05, 0.05])
min_max_scaler = MinMaxScaler()
X_train[['MQ2', 'MQ5', 'MQ7', 'MQ8', 'MQ135']] = min_max_scaler.fit_transform(X_train[['MQ2', 'MQ5', 'MQ7', 'MQ8', 'MQ135']])
X_test[['MQ2', 'MQ5', 'MQ7', 'MQ8', 'MQ135']] = min_max_scaler.transform(X_test[['MQ2', 'MQ5', 'MQ7', 'MQ8', 'MQ135']])

df = df.drop(['Serial Number', 'Corresponding Image Name'], axis=1)
X = df.drop(['Gas'], axis=1)
y = df['Gas']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

len(X_train)

for column in ['MQ2', 'MQ5','MQ6', 'MQ7', 'MQ8', 'MQ135']:
    X_train[column] = mstats.winsorize(X_train[column], limits=[0.05, 0.05])
    X_test[column] = mstats.winsorize(X_test[column], limits=[0.05, 0.05])

len(X_train)

min_max_scaler = MinMaxScaler()
X_train[['MQ2', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ135']] = min_max_scaler.fit_transform(X_train[['MQ2', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ135']])
X_test[['MQ2', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ135']] = min_max_scaler.transform(X_test[['MQ2', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ135']])

print("X_train after preprocessing:")
print(X_train.head())
print("\nX_test after preprocessing:")
print(X_test.head())

le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

svm_classifier = SVC(random_state=42)
rf_classifier = RandomForestClassifier(random_state=42)
knn_classifier = KNeighborsClassifier()

svm_classifier.fit(X_train, y_train_encoded)
svm_predictions = svm_classifier.predict(X_test)
svm_accuracy = accuracy_score(y_test_encoded, svm_predictions)
svm_classification_rep = classification_report(y_test_encoded, svm_predictions)

rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train_encoded)
rf_predictions = rf_classifier.predict(X_test)
rf_accuracy = accuracy_score(y_test_encoded, rf_predictions)
rf_classification_rep = classification_report(y_test_encoded, rf_predictions)

knn_classifier.fit(X_train, y_train_encoded)
knn_predictions = knn_classifier.predict(X_test)
knn_accuracy = accuracy_score(y_test_encoded, knn_predictions)
knn_classification_rep = classification_report(y_test_encoded, knn_predictions)

pca_train = PCA(n_components=2)
X_pca_train = pca_train.fit_transform(X_train)
df_train_pca = pd.DataFrame(X_pca_train, columns=['PCA1', 'PCA2'])
df_train_pca['Gas'] = y_train.reset_index(drop=True)
plt.figure(figsize=(10, 6))
for gas in df_train_pca['Gas'].unique():
    plt.scatter(df_train_pca[df_train_pca['Gas'] == gas]['PCA1'],
                df_train_pca[df_train_pca['Gas'] == gas]['PCA2'],
                label=f'{gas}')
plt.title('Original Distribution of Data Points for X_train')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.legend()
plt.show()

kmeans_train = KMeans(n_clusters=4, random_state=42)
X_train['Cluster'] = kmeans_train.fit_predict(X_train)
pca_train = PCA(n_components=2)
X_pca_train = pca_train.fit_transform(X_train)
X_train['PCA1'] = X_pca_train[:, 0]
X_train['PCA2'] = X_pca_train[:, 1]
plt.figure(figsize=(10, 6))
for cluster in X_train['Cluster'].unique():
    plt.scatter(X_train[X_train['Cluster'] == cluster]['PCA1'],
                X_train[X_train['Cluster'] == cluster]['PCA2'],
                label=f'Cluster {cluster}')
plt.title('K-Means Clustering Results for X_train')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.legend()
plt.show()

silhouette_train = silhouette_score(X_train.drop(['Cluster', 'PCA1', 'PCA2'], axis=1), X_train['Cluster'])
print("K-Means Clustering Results for X_train:")
print(f"Silhouette Score: {silhouette_train}")
print("\n" + "="*50 + "\n")

X_train

X_train = X_train.drop(['Cluster', 'PCA1', 'PCA2'], axis=1)
X_train

print("SVM Results:")
print(f"Accuracy: {svm_accuracy}")
print("Classification Report:")
print(svm_classification_rep)
print("\n" + "="*50 + "\n")

print("Random Forest Results:")
print(f"Accuracy: {rf_accuracy}")
print("Classification Report:")
print(rf_classification_rep)
print("\n" + "="*50 + "\n")

print("K-Nearest Neighbors Results:")
print(f"Accuracy: {knn_accuracy}")
print("Classification Report:")
print(knn_classification_rep)

"""****hyper parameter tuning :****"""

svm_classifier = SVC()
param_grid_svm = {'C': [0.1, 1, 10, 100], 'kernel': ['rbf']}
grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5)
grid_search_svm.fit(X_train, y_train_encoded)
best_params_svm = grid_search_svm.best_params_
best_svm_classifier = SVC(**best_params_svm)
best_svm_classifier.fit(X_train, y_train_encoded)
svm_predictions = best_svm_classifier.predict(X_test)
svm_accuracy = accuracy_score(y_test_encoded, svm_predictions)
svm_classification_rep = classification_report(y_test_encoded, svm_predictions)
print("Best SVM Parameters:", best_params_svm)
print("SVM Results with Best Parameters:")
print(f"Accuracy: {svm_accuracy}")
print("Classification Report:")
print(svm_classification_rep)

rf_classifier = RandomForestClassifier()
param_grid_rf = {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20, 30]}
grid_search_rf = GridSearchCV(rf_classifier, param_grid_rf, cv=5)
grid_search_rf.fit(X_train, y_train_encoded)
best_params_rf = grid_search_rf.best_params_
best_rf_classifier = RandomForestClassifier(**best_params_rf)
best_rf_classifier.fit(X_train, y_train_encoded)
rf_predictions = best_rf_classifier.predict(X_test)
rf_accuracy = accuracy_score(y_test_encoded, rf_predictions)
rf_classification_rep = classification_report(y_test_encoded, rf_predictions)
print("Best Random Forest Parameters:", best_params_rf)
print("Random Forest Results with Best Parameters:")
print(f"Accuracy: {rf_accuracy}")
print("Classification Report:")
print(rf_classification_rep)

knn_classifier = KNeighborsClassifier()
param_grid_knn = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}
grid_search_knn = GridSearchCV(knn_classifier, param_grid_knn, cv=5)
grid_search_knn.fit(X_train, y_train_encoded)
best_params_knn = grid_search_knn.best_params_
best_knn_classifier = KNeighborsClassifier(**best_params_knn)
best_knn_classifier.fit(X_train, y_train_encoded)
knn_predictions = best_knn_classifier.predict(X_test)
knn_accuracy = accuracy_score(y_test_encoded, knn_predictions)
knn_classification_rep = classification_report(y_test_encoded, knn_predictions)
print("Best K-Nearest Neighbors Parameters:", best_params_knn)
print("K-Nearest Neighbors Results with Best Parameters:")
print(f"Accuracy: {knn_accuracy}")
print("Classification Report:")
print(knn_classification_rep)

"""**#########################**

IMAGE PROCESSING

**#grey image**
"""

Smoke_folder_path = "/kaggle/working/Smoke"
Perfume_folder_path = "/kaggle/working/Perfume"
NoGas_folder_path = "/kaggle/working/NoGas"
Mixture_folder_path = "/kaggle/working/Mixture"
df = pd.read_csv('/kaggle/working/zkwgkjkjn9-2/Gas Sensors Measurements/Gas_Sensors_Measurements.csv')
def read_and_preprocess_images(folder_path):
    images = []
    labels = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.png'):
            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
            img = cv2.resize(img, (100, 100))  # Resize image to a fixed size
            images.append(img)
            labels.append(folder_path.split('/')[-1])  # Use folder name as label
    return images, labels

smoke_images, smoke_labels = read_and_preprocess_images(Smoke_folder_path)
perfume_images, perfume_labels = read_and_preprocess_images(Perfume_folder_path)
no_gas_images, no_gas_labels = read_and_preprocess_images(NoGas_folder_path)
mixture_images, mixture_labels = read_and_preprocess_images(Mixture_folder_path)

all_images = np.concatenate([smoke_images, perfume_images, no_gas_images, mixture_images])
all_labels = np.concatenate([smoke_labels, perfume_labels, no_gas_labels, mixture_labels])
label_encoder = LabelEncoder()
all_labels_encoded = label_encoder.fit_transform(all_labels)
all_labels_one_hot = to_categorical(all_labels_encoded)

X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels_one_hot, test_size=0.2, random_state=42)

X_train

X_train.shape

y_train.shape

X_train_normalized = X_train / 255.0
X_test_normalized = X_test / 255.0
print("Normalized X_train shape:", X_train_normalized.shape)
print("Normalized X_test shape:", X_test_normalized.shape)

X_train_np = np.array(X_train_normalized)
X_test_np = np.array(X_test_normalized)
y_train_np = np.array(y_train)
y_test_np = np.array(y_test)
X_train_np = X_train_np.reshape((X_train_np.shape[0], X_train_np.shape[1], X_train_np.shape[2], 1))
X_test_np = X_test_np.reshape((X_test_np.shape[0], X_test_np.shape[1], X_test_np.shape[2], 1))
model = Sequential()
model.add(Conv2D(16, (3, 3), padding='same', input_shape=X_train_np.shape[1:], activation='relu'))
model.add(MaxPooling2D(2))
model.add(Dropout(0.2))
model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(2))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(4, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train_np, y_train_np, epochs=10, validation_data=(X_test_np, y_test_np))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

pd.DataFrame(history.history).plot()

"""**colored image**

**colored image**
"""

def read_and_preprocess_images(folder_path):
    images = []
    labels = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.png'):
            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_COLOR)  # Read in color
            img = cv2.resize(img, (100, 100))  # Resize image to a fixed size
            images.append(img)
            labels.append(folder_path.split('/')[-1])  # Use folder name as label
    return images, labels
smoke_images, smoke_labels = read_and_preprocess_images(Smoke_folder_path)
perfume_images, perfume_labels = read_and_preprocess_images(Perfume_folder_path)
no_gas_images, no_gas_labels = read_and_preprocess_images(NoGas_folder_path)
mixture_images, mixture_labels = read_and_preprocess_images(Mixture_folder_path)
all_images = np.concatenate([smoke_images, perfume_images, no_gas_images, mixture_images])
all_labels = np.concatenate([smoke_labels, perfume_labels, no_gas_labels, mixture_labels])
label_encoder = LabelEncoder()
all_labels_encoded = label_encoder.fit_transform(all_labels)
all_labels_one_hot = to_categorical(all_labels_encoded)

X_train_colored, X_test_colored, y_train, y_test = train_test_split(all_images, all_labels_one_hot, test_size=0.2, random_state=42)

X_train_colored.shape

X_train_normalized = X_train_colored / 255.0
X_test_normalized = X_test_colored / 255.0
print("Normalized X_train shape:", X_train_normalized.shape)
print("Normalized X_test shape:", X_test_normalized.shape)

X_train_np = np.array(X_train_normalized)
X_test_np = np.array(X_test_normalized)
y_train_np = np.array(y_train)
y_test_np = np.array(y_test)
model = Sequential()
model.add(Conv2D(16, (3, 3), padding='same', input_shape=(100, 100, 3), activation='relu'))
model.add(MaxPooling2D(2))
model.add(Dropout(0.2))
model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(2))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(4, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train_np, y_train_np, epochs=10, validation_data=(X_test_np, y_test_np))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

pd.DataFrame(history.history).plot()

test_loss, test_accuracy = model.evaluate(X_test_np, y_test_np)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')
print(f'Test Loss: {test_loss:.4f}')